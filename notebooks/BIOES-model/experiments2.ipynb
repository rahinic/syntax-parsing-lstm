{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h1> <div align=\"center\"> Compositional Neural Network </div></h1>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\r\n",
    "from datasetConLL2003 import SlidingWindowDataset\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "ds = SlidingWindowDataset(\"C:/Users/rahin/projects/paper-draft-03/data/raw/ConLL2003-bioes-valid.txt\")\r\n",
    "x1, x2, y = ds.load_dictionaries()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading dictionaries...\n",
      "done\n",
      "Performing dataset pre-processing activities...\n",
      "loading dataset: ConLL2003-bioes-valid.txt\n",
      "done\n",
      "Parsing the dataset now...\n",
      "converting tokens to indices to tensors\n",
      "done\n",
      "Length matches! Hurray!\n",
      "loading dictionaries...\n",
      "done\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "x2.keys() #VBG, -X-, ("
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['VBZ', '\"', 'WDT', 'DT', 'VBG', 'MD', 'NN', 'WP$', 'NNS', 'PDT', 'WP', '-X-', 'WRB', 'NNPS', 'PRP', 'JJ', 'SYM', '(', 'PRP$', 'EX', 'VBD', \"''\", 'POS', 'RP', ')', ',', 'VBN', 'CD', 'JJS', 'LS', 'NNP', 'TO', 'VB', 'VBP', ':', 'JJR', 'RB', 'CC', '.', 'RBR', '$', 'FW', 'NN|SYM', 'UH', 'RBS', 'IN', 'PADDING'])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "sentence = \"Leicestershire beat Somerset by an innings and 39 runs\"\r\n",
    "pos = \"VB NNP IN DT NN CC CD NNS .\"\r\n",
    "tok_in_sent, pos_in_sent = sentence.split(' '), pos.split(' ')\r\n",
    "\r\n",
    "for padding in range(50-len(sentence.split(' '))):\r\n",
    "    tok_in_sent.append('PADDING')\r\n",
    "    pos_in_sent.append('PADDING')\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "sent_with_tags_idx = []\r\n",
    "for word,pos in zip(tok_in_sent, pos_in_sent):\r\n",
    "    features = x1[word]+x2[pos]\r\n",
    "    sent_with_tags_idx.append(features)\r\n",
    "\r\n",
    "sent_with_tags_tensor = torch.tensor(sent_with_tags_idx, dtype=torch.int64)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "sent_with_tags_tensor"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([30003, 20574, 12800, 23952,  9699, 13617, 29459, 25035,  1505, 30338,\n",
       "        30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338,\n",
       "        30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338,\n",
       "        30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338,\n",
       "        30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predict tags"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from modelConLL2003 import RNNBIOESTagger\r\n",
    "from datasetConLL2003 import SlidingWindowDataset\r\n",
    "import torch\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "# read this seq2seq model: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html --> for understanding embedding dimension and output dimension  \r\n",
    "VOCAB_SIZE = len(x1)+len(x2)+2\r\n",
    "EMBED_DIM = 100\r\n",
    "HIDDEN_DIM = 64\r\n",
    "NUM_LAYERS = 2\r\n",
    "NUM_OF_CLASSES = len(y)+1\r\n",
    "N_EPOCHS = 10\r\n",
    "LEARNING_RATE = 0.01\r\n",
    "BATCH_SIZE = 32\r\n",
    "\r\n",
    "print(f\"Our vocab size to the model is therefore: {VOCAB_SIZE}\")\r\n",
    "################################### 02. NN Model  ########################################\r\n",
    "\r\n",
    "print(\"Step 02. builing the model...\")\r\n",
    "model = RNNBIOESTagger(embedding_dimension= EMBED_DIM,\r\n",
    "                            vocabulary_size=VOCAB_SIZE,\r\n",
    "                            hidden_dimension=HIDDEN_DIM,\r\n",
    "                            num_of_layers=NUM_LAYERS,\r\n",
    "                            dropout=0.2,\r\n",
    "                            output_dimension=NUM_OF_CLASSES)\r\n",
    "print(\"----------------------------------------------------------------\")\r\n",
    "print(\"Done! here is our model:\")\r\n",
    "print(model)\r\n",
    "print(\"----------------------------------------------------------------\")\r\n",
    "\r\n",
    "\r\n",
    "model.load_state_dict(torch.load(\"C:/Users/rahin/projects/paper-draft-03/notebooks/conLLmodel.pth\"))\r\n",
    "model.eval()\r\n",
    "\r\n",
    "idx_to_BIOES = {}\r\n",
    "print(\"Lets make predictions\")\r\n",
    "\r\n",
    "validation_dataset = DataLoader(dataset=SlidingWindowDataset(\"C:/Users/rahin/projects/paper-draft-03/data/raw/ConLL2003-bioes-valid.txt\"),\r\n",
    "                                batch_size=64,\r\n",
    "                                shuffle=True)\r\n",
    "\r\n",
    "for key, value in y.items():\r\n",
    "    idx_to_BIOES[value] = key\r\n",
    "\r\n",
    "# print(idx_to_BIOES)\r\n",
    "\r\n",
    "def predict(sentence, model):\r\n",
    "\r\n",
    "    # token idx to tensor conversion\r\n",
    "\r\n",
    "    idx_to_torch01 = torch.tensor(sentence, dtype=torch.int64)\r\n",
    "    idx_to_torch = idx_to_torch01.unsqueeze(1).T\r\n",
    "\r\n",
    "\r\n",
    "    with torch.no_grad():\r\n",
    "        output = model(idx_to_torch)\r\n",
    "        predicted_ouput=torch.argmax(output,dim=2)\r\n",
    "        \r\n",
    "        predicted_labels = []\r\n",
    "\r\n",
    "        for pred in predicted_ouput:\r\n",
    "            for i in pred:\r\n",
    "                predicted_labels.append(idx_to_BIOES[int(i)])\r\n",
    "\r\n",
    "        return output, predicted_labels\r\n",
    "\r\n",
    "model = model.to(\"cpu\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Our vocab size to the model is therefore: 30340\n",
      "Step 02. builing the model...\n",
      "----------------------------------------------------------------\n",
      "Done! here is our model:\n",
      "RNNBIOESTagger(\n",
      "  (embedding): Embedding(30340, 100)\n",
      "  (lstm): LSTM(100, 64, num_layers=2, batch_first=True, dropout=0.2)\n",
      "  (fc): Linear(in_features=64, out_features=35, bias=True)\n",
      "  (activation_fn): Tanh()\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "Lets make predictions\n",
      "loading dictionaries...\n",
      "done\n",
      "Performing dataset pre-processing activities...\n",
      "loading dataset: ConLL2003-bioes-valid.txt\n",
      "done\n",
      "Parsing the dataset now...\n",
      "converting tokens to indices to tensors\n",
      "done\n",
      "Length matches! Hurray!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "probs, preds = predict(sent_with_tags_tensor, model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-5-47a4d1d54f94>:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  idx_to_torch01 = torch.tensor(sentence, dtype=torch.int64)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "preds_only_tokens = []\r\n",
    "\r\n",
    "for tag in preds:\r\n",
    "    if tag !=\"PADDING\":\r\n",
    "        preds_only_tokens.append(tag)\r\n",
    "preds_only_tokens\r\n",
    "preds_only_tokens = ['B-VP', 'B-NP', 'I-NP', 'E-NP', 'B-VP', 'B-NP', 'B-VP', 'E-VP', 'B-NP'] #corrected"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['B-VP', 'B-NP', 'I-NP', 'I-NP', 'B-VP', 'B-NP', 'B-VP', 'I-VP', 'B-NP']"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "75c4db28bb58e6de10e05be21b6046b5ba21d9aba4af4007d97c2f3325bc0896"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('tf': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}