{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: loading Train/Test/Validation datasets...\n",
      "****************************************************************************************************\n",
      "loading dictionaries...\n",
      "done\n",
      "Performing dataset pre-processing activities...\n",
      "loading dataset: ConLL2003-bioes-valid.txt\n",
      "done\n",
      "Parsing the dataset now...\n",
      "converting tokens to indices to tensors\n",
      "done\n",
      "Length matches! Hurray!\n",
      "****************************************************************************************************\n",
      "All datasets successfully loaded!\n"
     ]
    }
   ],
   "source": [
    "import torch\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from torch import nn\r\n",
    "import torch.optim as optim\r\n",
    "from datasetConLL2003 import SlidingWindowDataset\r\n",
    "from modelConLL2003 import RNNBIOESTagger\r\n",
    "\r\n",
    "print(\"Step 1: loading Train/Test/Validation datasets...\")\r\n",
    "print(\"*\"*100)     \r\n",
    "validation_dataset = DataLoader(dataset=SlidingWindowDataset(\"C:/Users/rahin/projects/paper-draft-03/data/raw/ConLL2003-bioes-valid.txt\"),\r\n",
    "                                batch_size=64,\r\n",
    "                                shuffle=False)\r\n",
    "print(\"*\"*100)                                \r\n",
    "\r\n",
    "print(\"All datasets successfully loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18122, 22892,  6603, 11657, 14828,  4595, 22902, 21347,  8802,  9933,\n",
      "        26565, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338,\n",
      "        30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338,\n",
      "        30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338,\n",
      "        30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338])\n",
      "tensor([10, 26, 15, 26, 24,  8, 26, 24, 24, 24, 29, 34, 34, 34, 34, 34, 34, 34,\n",
      "        34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,\n",
      "        34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34])\n",
      "tensor([14501,  4466, 14760, 10226, 15579,  9637, 22776, 28907, 13927, 21022,\n",
      "        19107, 26859, 11840,  3781,  1436, 28233, 29469, 13546,  1280,  3373,\n",
      "        15709, 26829, 15174, 21022,   856, 11350,  4977, 26553, 12099, 12933,\n",
      "        12624, 10371, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338,\n",
      "        30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338])\n",
      "tensor([26, 24, 26, 24, 24, 26, 24, 30, 26,  8, 26, 15, 26, 24, 24, 24, 24, 24,\n",
      "        24, 30, 15, 27, 25,  8, 26, 24,  8, 26,  8, 26, 24, 29, 34, 34, 34, 34,\n",
      "        34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34])\n",
      "tensor([26770,  9338, 21230,  1412,   856,  3988,  4977, 29306, 24280, 12099,\n",
      "         5630, 12744,  4089, 14104, 15212, 15292,    46,  2607,  4089, 27212,\n",
      "        16693, 23868, 14952, 12099, 11735, 18096, 24999,  4746, 17921,  4977,\n",
      "        14069,  4089, 29469, 19761, 12624, 10371, 13852,  4281, 13749, 30338,\n",
      "        30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338])\n",
      "tensor([11, 26, 30,  8, 26, 24,  8, 26, 24,  8, 26,  8, 15,  8, 26, 24, 26, 24,\n",
      "         4, 26, 30,  8, 26,  8, 26, 24, 26, 24, 24,  8, 26, 15,  4, 26, 24, 24,\n",
      "        24, 24, 29, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34])\n",
      "tensor([15369, 20501, 11981, 28319, 23485, 22169,  4883,  4821,  4195,  4089,\n",
      "        29469, 29441, 26077, 24700, 12099,  9696, 25176, 29344,  4977, 24626,\n",
      "        21310, 12933,  2047,  4089, 14829, 29230, 12933, 26946, 19643, 19825,\n",
      "         5000, 13232,  1515, 29441, 28646, 20135, 30338, 30338, 30338, 30338,\n",
      "        30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338])\n",
      "tensor([26, 24, 24, 30, 31, 14, 18, 26, 24,  4,  4, 30, 31, 31,  8, 26, 24, 24,\n",
      "         8, 26,  8, 26, 24,  4, 14,  8, 26, 24, 24, 24, 26, 26, 30, 30, 26, 29,\n",
      "        34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34])\n",
      "tensor([15369,  1201, 10596, 23467,  3373, 26770, 14860, 24093,  7007, 23994,\n",
      "        12933, 20809,  4977,  4844,  8866, 12985,  4514, 26770, 26859, 28115,\n",
      "        17703, 24856,  6478, 19206,  9087, 18099, 21230, 13678, 12933,  8393,\n",
      "         1506, 22208, 29108,  8641, 19450, 23863, 27641, 23651, 23868, 13941,\n",
      "        21230,  5292, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338])\n",
      "tensor([26, 24, 30, 26, 30, 15, 26, 24, 30,  8, 26, 24,  8, 26, 15, 26, 15,  4,\n",
      "         4, 26, 24, 24, 30, 31, 31, 26, 30, 27, 26, 24, 30, 31, 31,  8, 26, 17,\n",
      "        26, 24,  8, 26, 30, 13, 34, 34, 34, 34, 34, 34, 34, 34])\n",
      "tensor([19824, 21230, 26697,  8641, 12579, 26299,  8866, 27084,  4514,  2163,\n",
      "        30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338,\n",
      "        30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338,\n",
      "        30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338,\n",
      "        30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338, 30338])\n",
      "tensor([26, 30, 31,  8, 26, 24,  4, 26, 15, 29, 34, 34, 34, 34, 34, 34, 34, 34,\n",
      "        34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,\n",
      "        34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34])\n"
     ]
    }
   ],
   "source": [
    "for idx, (sample, label) in enumerate(validation_dataset):\r\n",
    "\r\n",
    "    if idx > 5:\r\n",
    "        break\r\n",
    "\r\n",
    "    print(sample[0])\r\n",
    "    print(label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\r\n",
    "a = torch.tensor([[30303, 15579, 25899, 27259, 25977, 25706,   353, 15594,  5630, 23868,\r\n",
    "        29209, 21022, 19729,  1960, 30001, 20564, 12785, 23994,  9696, 13586,\r\n",
    "        29469, 25054,  1475, 19127, 11985,  3170, 21310, 17047, 14281, 12099,\r\n",
    "        12933,  8141,  4977, 12933, 27420, 20205,    0,    0,    0,    0]])           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 40])\n",
      "torch.Size([1, 40, 100])\n",
      "tensor([[[-1.3923, -1.1445,  0.1384,  ...,  0.2422,  0.4852,  0.4902],\n",
      "         [-0.5394, -1.0573, -1.4659,  ..., -1.3343,  0.4385, -0.3999],\n",
      "         [ 0.1653,  0.0355,  0.1190,  ..., -0.0938,  0.1412, -1.7612],\n",
      "         ...,\n",
      "         [-0.4802, -0.5822, -0.7314,  ..., -0.1073, -0.8257,  0.8428],\n",
      "         [-0.4802, -0.5822, -0.7314,  ..., -0.1073, -0.8257,  0.8428],\n",
      "         [-0.4802, -0.5822, -0.7314,  ..., -0.1073, -0.8257,  0.8428]]],\n",
      "       grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\r\n",
    "word_embeddings = nn.Embedding(50000, 100)\r\n",
    "embedded = word_embeddings(a)\r\n",
    "print(a.size())\r\n",
    "print(embedded.size())\r\n",
    "print(embedded)\r\n",
    "# a.view(5,1,-1)\r\n",
    "#a.view(len(sample), 1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-87d39ca5e327>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "a[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor([[-0.9557,  0.8384,  0.9705,  ..., -0.8514,  0.0321, -0.9883],\r\n",
    "        [-0.9557,  0.8384,  0.9705,  ..., -0.8514,  0.0321, -0.9883],\r\n",
    "        [-0.9557,  0.8384,  0.9705,  ..., -0.8514,  0.0321, -0.9883],\r\n",
    "        ...,\r\n",
    "        [-0.9557,  0.8384,  0.9705,  ..., -0.8514,  0.0321, -0.9883],\r\n",
    "        [-0.9557,  0.8384,  0.9705,  ..., -0.8514,  0.0321, -0.9883],\r\n",
    "        [-0.9557,  0.8384,  0.9705,  ..., -0.8514,  0.0321, -0.9883]],\r\n",
    "       grad_fn=<SelectBackward>)\r\n",
    "tensor([[-0.0160,  0.1855,  0.0073,  ..., -0.0230,  0.0488, -0.0477],\r\n",
    "        [ 0.0245,  0.1932,  0.0244,  ..., -0.0372,  0.1381, -0.0802],\r\n",
    "        [ 0.0274,  0.2338,  0.0461,  ..., -0.0484,  0.1108, -0.0983],\r\n",
    "        ...,\r\n",
    "        [-0.0761,  0.8270, -0.0747,  ..., -0.3217,  0.2419, -0.4042],\r\n",
    "        [-0.0813,  0.8255,  0.0396,  ..., -0.2542,  0.3420, -0.4402],\r\n",
    "        [-0.0663,  0.8745,  0.0097,  ..., -0.3122,  0.2481, -0.3710]],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2510, 0.1991, 0.1559],\n",
       "         [0.1179, 0.1065, 0.8308]],\n",
       "\n",
       "        [[0.2598, 0.8629, 0.1640],\n",
       "         [0.8153, 0.2240, 0.6898]]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = torch.rand(2,2,3)\r\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2510, 0.1179],\n",
      "         [0.1991, 0.1065],\n",
      "         [0.1559, 0.8308]],\n",
      "\n",
      "        [[0.2598, 0.8153],\n",
      "         [0.8629, 0.2240],\n",
      "         [0.1640, 0.6898]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 1],\n",
       "        [1, 0, 1]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample2 = sample.permute(0,2,1)\r\n",
    "print(sample2)\r\n",
    "torch.argmax(sample2, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{tensor([[0, 2],\n",
      "        [1, 0]])}\n"
     ]
    }
   ],
   "source": [
    "a = torch.argmax(sample, dim=2)\r\n",
    "print({a})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('embedding.weight',\n",
       "              tensor([[-1.3641,  0.3324,  0.7190,  ..., -0.5538,  1.7921, -0.1599],\n",
       "                      [-0.5421, -0.3172,  0.6984,  ...,  1.0932, -0.3610,  0.8771],\n",
       "                      [-0.3839,  0.7729, -0.3392,  ..., -0.5566, -0.1870, -0.9657],\n",
       "                      ...,\n",
       "                      [-1.4310, -0.4061, -0.2849,  ..., -0.8882, -0.1645, -0.3241],\n",
       "                      [-1.0102, -1.5329,  0.3289,  ...,  0.9910, -0.7470,  1.1637],\n",
       "                      [-1.4748,  0.6631, -0.5386,  ..., -3.4331, -1.1510,  0.6949]])),\n",
       "             ('lstm.weight_ih_l0',\n",
       "              tensor([[ 0.0955, -0.0867, -0.0028,  ...,  0.0487, -0.0152, -0.0374],\n",
       "                      [ 0.0479,  0.0455,  0.0779,  ...,  0.0607, -0.0685, -0.0260],\n",
       "                      [-0.0570,  0.0889, -0.0931,  ..., -0.0483, -0.0595, -0.0820],\n",
       "                      ...,\n",
       "                      [-0.0519, -0.0474,  0.0269,  ..., -0.0555,  0.0673, -0.0313],\n",
       "                      [ 0.0303,  0.0352, -0.1120,  ..., -0.0700, -0.0448, -0.0938],\n",
       "                      [ 0.1147, -0.0577,  0.0004,  ...,  0.0948, -0.0619,  0.0261]])),\n",
       "             ('lstm.weight_hh_l0',\n",
       "              tensor([[-0.0853,  0.1130, -0.1072,  ...,  0.0364, -0.0047, -0.0575],\n",
       "                      [ 0.0359, -0.0168, -0.0612,  ..., -0.1144,  0.0330,  0.0693],\n",
       "                      [-0.0246, -0.1069,  0.0352,  ...,  0.0091,  0.1006,  0.0733],\n",
       "                      ...,\n",
       "                      [-0.0118,  0.0875,  0.0784,  ...,  0.0280,  0.0747, -0.0524],\n",
       "                      [ 0.0201, -0.0948, -0.0150,  ..., -0.1226,  0.0090,  0.1153],\n",
       "                      [-0.0348, -0.0989, -0.0294,  ...,  0.0023,  0.1099,  0.0137]])),\n",
       "             ('lstm.bias_ih_l0',\n",
       "              tensor([ 0.1205, -0.0265, -0.0586, -0.0861,  0.1438,  0.0065,  0.0327,  0.0695,\n",
       "                       0.0881,  0.1250, -0.0405, -0.0757,  0.0567,  0.0719, -0.0460,  0.0583,\n",
       "                       0.0316,  0.0143,  0.0453, -0.0862,  0.0063, -0.0228,  0.0589,  0.0309,\n",
       "                      -0.0887,  0.0134, -0.0270,  0.1167,  0.1121,  0.0996,  0.1286, -0.0524,\n",
       "                       0.0035,  0.1214, -0.0880, -0.0831,  0.0813, -0.0456, -0.0329, -0.0987,\n",
       "                       0.0185, -0.0912, -0.0009, -0.0742,  0.1194,  0.1157,  0.0062,  0.0920,\n",
       "                       0.0683,  0.1039,  0.0650, -0.1057, -0.0202,  0.0550,  0.0176,  0.0598,\n",
       "                      -0.0163, -0.0946, -0.0149, -0.0628, -0.0142,  0.0314,  0.0723,  0.0786,\n",
       "                       0.0099,  0.0998, -0.0172,  0.0324, -0.0458, -0.0456,  0.1230, -0.0245,\n",
       "                       0.0105,  0.0022,  0.0362,  0.0659,  0.0382, -0.0431, -0.0772,  0.0401,\n",
       "                      -0.0394,  0.0791,  0.1113,  0.1193, -0.1210,  0.0149, -0.0562,  0.0379,\n",
       "                       0.0168, -0.0028,  0.1181,  0.0683, -0.0156,  0.0438, -0.0741,  0.1036,\n",
       "                       0.0614,  0.0751,  0.1140, -0.0850,  0.0495,  0.0907, -0.1074,  0.0349,\n",
       "                      -0.0980, -0.1053,  0.0342, -0.0668,  0.0129, -0.0950,  0.0208, -0.0429,\n",
       "                       0.1033,  0.1136,  0.0993,  0.1091,  0.0501,  0.0208,  0.1173, -0.0613,\n",
       "                       0.1082,  0.0648,  0.1138, -0.0047, -0.0011,  0.0512,  0.0900, -0.0194,\n",
       "                       0.0302, -0.0959,  0.2013, -0.0096,  0.1757, -0.0679,  0.0194,  0.0818,\n",
       "                      -0.0450,  0.1093, -0.1202, -0.2078, -0.0882, -0.1536, -0.1077,  0.0381,\n",
       "                      -0.1961,  0.0840, -0.0830, -0.0528,  0.1376, -0.1104,  0.0032,  0.0474,\n",
       "                       0.0669, -0.0017, -0.0475,  0.0140, -0.0628,  0.0440, -0.2086, -0.0868,\n",
       "                       0.1134, -0.0480,  0.0270,  0.1314, -0.1023, -0.1034,  0.1543, -0.0266,\n",
       "                      -0.0349,  0.1297, -0.0370,  0.0316,  0.0871, -0.1519,  0.1965, -0.0442,\n",
       "                       0.1425,  0.0292, -0.0350,  0.0682, -0.0113, -0.0260,  0.0156,  0.0833,\n",
       "                       0.0930, -0.0262, -0.0510,  0.0879,  0.0737, -0.1454, -0.2043, -0.1442,\n",
       "                       0.1071, -0.0779,  0.1435,  0.0210,  0.0891, -0.0526, -0.0278,  0.0964,\n",
       "                       0.0072,  0.0271,  0.0157,  0.1023,  0.0208,  0.0572, -0.0844,  0.0045,\n",
       "                       0.0925,  0.1002, -0.0668,  0.0606, -0.1188,  0.0413, -0.0863,  0.0028,\n",
       "                      -0.0859, -0.0106, -0.1041, -0.0703, -0.0946,  0.0292, -0.0352,  0.0150,\n",
       "                      -0.0539,  0.0137,  0.0682,  0.0835,  0.0626,  0.0990, -0.0851,  0.0149,\n",
       "                      -0.1130, -0.0890, -0.0727, -0.0953, -0.0831, -0.0653,  0.1092, -0.0438,\n",
       "                       0.0803,  0.0481,  0.0774, -0.0932,  0.0638, -0.0815,  0.0182,  0.1263,\n",
       "                      -0.0522, -0.0601, -0.0675, -0.0040, -0.0168,  0.1050,  0.0793,  0.1851])),\n",
       "             ('lstm.bias_hh_l0',\n",
       "              tensor([ 0.1052, -0.0849,  0.1225,  0.1090,  0.1174,  0.1286, -0.1112,  0.0845,\n",
       "                      -0.0958,  0.1255, -0.0873, -0.0705,  0.0032,  0.1073,  0.0830, -0.1121,\n",
       "                       0.1108, -0.0362,  0.0456,  0.0250,  0.0275,  0.0998,  0.0878,  0.0607,\n",
       "                      -0.0467, -0.0066, -0.0897,  0.0982, -0.0587, -0.0814,  0.0204,  0.0986,\n",
       "                      -0.0970,  0.0312,  0.0567, -0.0223,  0.0917, -0.0129, -0.0480,  0.0175,\n",
       "                      -0.0420,  0.1219,  0.0359,  0.0769,  0.0846,  0.1132,  0.0706,  0.1065,\n",
       "                       0.0344, -0.0582,  0.1368, -0.0143,  0.0877, -0.0178,  0.0763, -0.0873,\n",
       "                      -0.0569,  0.0710,  0.0098,  0.0237,  0.0054, -0.0686,  0.1240,  0.1290,\n",
       "                       0.0978, -0.0056,  0.0535,  0.0255,  0.0928, -0.1229,  0.0419,  0.1092,\n",
       "                       0.1060, -0.0060,  0.0692,  0.1160,  0.0762,  0.0432,  0.0426,  0.0607,\n",
       "                      -0.0880, -0.0263, -0.1154, -0.0111,  0.0385, -0.0505, -0.0892,  0.0898,\n",
       "                       0.0648,  0.0749,  0.0400,  0.1017,  0.0050, -0.0176, -0.0442,  0.0987,\n",
       "                       0.0041,  0.0129,  0.0265, -0.0441, -0.0242, -0.1234, -0.1054,  0.0852,\n",
       "                      -0.0857,  0.0890, -0.0574,  0.0545, -0.0834,  0.0473,  0.0395,  0.0251,\n",
       "                       0.0125, -0.0947, -0.0815,  0.0501, -0.0735, -0.1263,  0.0323, -0.1304,\n",
       "                       0.0449,  0.0463,  0.0673,  0.1156, -0.1279, -0.0655,  0.0210, -0.0730,\n",
       "                       0.0656,  0.0832,  0.1969,  0.0908,  0.2125, -0.0913,  0.0537,  0.0455,\n",
       "                       0.0160,  0.0970, -0.0438, -0.1099, -0.1631, -0.2405, -0.0563,  0.0499,\n",
       "                      -0.1352,  0.1044, -0.0198, -0.0509, -0.0173, -0.1529,  0.0189,  0.0607,\n",
       "                      -0.0059,  0.0485, -0.0712,  0.1850, -0.1084, -0.0488,  0.0123, -0.0313,\n",
       "                       0.1419, -0.1026,  0.1113,  0.0197, -0.0010, -0.1689,  0.0916, -0.1215,\n",
       "                      -0.0733, -0.0089, -0.0039, -0.1058,  0.0680, -0.0359,  0.1397, -0.0669,\n",
       "                      -0.0186, -0.1572, -0.0121,  0.1030,  0.1304,  0.1440, -0.0512, -0.0841,\n",
       "                       0.0355,  0.0979, -0.0077, -0.0149,  0.0008, -0.0382, -0.0535, -0.1102,\n",
       "                       0.1262,  0.0741, -0.0204, -0.0189,  0.0570,  0.0993,  0.0853, -0.0489,\n",
       "                      -0.0006,  0.0790,  0.0686, -0.0344, -0.0090,  0.1573,  0.1357,  0.0854,\n",
       "                      -0.0327,  0.0081,  0.0028, -0.0907, -0.1222,  0.1132, -0.0998,  0.0447,\n",
       "                       0.0473,  0.0219, -0.0737,  0.0363,  0.0326,  0.0003, -0.1026, -0.1155,\n",
       "                       0.0944,  0.0412, -0.0952,  0.0149,  0.0235, -0.0112, -0.0324,  0.0178,\n",
       "                       0.1235,  0.0937, -0.0617,  0.1074, -0.0772,  0.0728, -0.0995,  0.0878,\n",
       "                      -0.0718, -0.0468,  0.0945,  0.0227,  0.1267, -0.0825, -0.1271,  0.0752,\n",
       "                      -0.0143, -0.0542, -0.0400,  0.0097, -0.0203, -0.0839, -0.0226,  0.0064])),\n",
       "             ('lstm.weight_ih_l1',\n",
       "              tensor([[ 0.0885, -0.0626,  0.0630,  ..., -0.1051,  0.0014, -0.0557],\n",
       "                      [-0.0007, -0.0161, -0.0488,  ..., -0.0058,  0.0408,  0.1004],\n",
       "                      [ 0.0614, -0.1249, -0.0286,  ...,  0.0441,  0.0329,  0.0845],\n",
       "                      ...,\n",
       "                      [ 0.0112,  0.0141, -0.0015,  ..., -0.1299, -0.1041, -0.0986],\n",
       "                      [ 0.1103, -0.0247, -0.0743,  ..., -0.0040,  0.0550, -0.1239],\n",
       "                      [-0.0643, -0.0998, -0.0479,  ...,  0.0172, -0.0883, -0.0799]])),\n",
       "             ('lstm.weight_hh_l1',\n",
       "              tensor([[-0.0729,  0.0891, -0.0332,  ..., -0.0179,  0.0374, -0.0032],\n",
       "                      [ 0.1230,  0.0359,  0.0390,  ...,  0.0322, -0.0354, -0.1194],\n",
       "                      [ 0.0033,  0.0557,  0.0740,  ..., -0.0480,  0.0549,  0.0778],\n",
       "                      ...,\n",
       "                      [-0.0436,  0.0654,  0.0796,  ...,  0.1167, -0.0270, -0.0652],\n",
       "                      [-0.0371,  0.0865,  0.0853,  ...,  0.0953, -0.0047,  0.0016],\n",
       "                      [-0.0803,  0.1542, -0.0665,  ...,  0.0165, -0.0442, -0.0929]])),\n",
       "             ('lstm.bias_ih_l1',\n",
       "              tensor([ 0.2014,  0.0149,  0.0111,  0.0462,  0.0572, -0.0017,  0.0564,  0.0422,\n",
       "                       0.1537, -0.0172,  0.1283, -0.0188, -0.0172,  0.0394,  0.1743, -0.0075,\n",
       "                       0.0157,  0.1005,  0.0489,  0.0764, -0.0355,  0.1424,  0.2247,  0.0347,\n",
       "                       0.0422, -0.0164,  0.0848,  0.0859,  0.1876,  0.1181,  0.1163,  0.0278,\n",
       "                       0.0104,  0.1506, -0.0580,  0.1031,  0.0473,  0.1521,  0.1451,  0.0966,\n",
       "                      -0.0349,  0.0855, -0.0353,  0.0918,  0.1331,  0.0282,  0.0617, -0.1020,\n",
       "                      -0.0039,  0.0860,  0.1389,  0.0080,  0.2153,  0.1485,  0.1464, -0.0640,\n",
       "                       0.0845, -0.0010,  0.0848, -0.0369,  0.0243,  0.1572,  0.1080,  0.1663,\n",
       "                       0.0377,  0.0309,  0.0117,  0.1553, -0.0475,  0.1125,  0.0175,  0.0137,\n",
       "                      -0.0290,  0.0558,  0.1324,  0.0809,  0.0914, -0.0654,  0.1284, -0.0483,\n",
       "                       0.1078,  0.1631,  0.1831, -0.0039, -0.0559,  0.1179,  0.0965, -0.0377,\n",
       "                       0.0601,  0.0246,  0.1937,  0.1227,  0.0320,  0.0969,  0.0023,  0.0376,\n",
       "                       0.1905,  0.1026,  0.0399,  0.0226, -0.0992,  0.1728,  0.0457,  0.0591,\n",
       "                      -0.0676,  0.0422,  0.1279,  0.0353, -0.0804, -0.0640,  0.0057, -0.0397,\n",
       "                       0.0928, -0.0156, -0.0441, -0.0636, -0.0504, -0.0673,  0.0086,  0.0132,\n",
       "                       0.1092, -0.0970, -0.0272,  0.0396,  0.0596,  0.0451, -0.0490,  0.0181,\n",
       "                       0.2140,  0.0547,  0.0992, -0.2559,  0.2077,  0.0789,  0.2620, -0.0812,\n",
       "                       0.2698,  0.1601,  0.1422,  0.2774, -0.2082, -0.1620, -0.2703,  0.2547,\n",
       "                       0.1502, -0.1742,  0.4186, -0.1264, -0.0472,  0.2721, -0.3541,  0.1624,\n",
       "                       0.1633, -0.2116, -0.2879,  0.2124,  0.2581, -0.2854, -0.2528,  0.1797,\n",
       "                       0.2884,  0.0060, -0.1366,  0.0885,  0.0245, -0.3525,  0.2020, -0.1606,\n",
       "                       0.1508, -0.1667,  0.3446,  0.1756, -0.1481, -0.1817, -0.2756,  0.1266,\n",
       "                       0.2500, -0.4220,  0.1654,  0.1860, -0.1857, -0.0167, -0.2094,  0.1864,\n",
       "                       0.1229, -0.1654,  0.1519, -0.0305,  0.1301,  0.2399,  0.0881,  0.2672,\n",
       "                       0.1962,  0.1766, -0.0239,  0.0581, -0.0282,  0.0253,  0.2489, -0.0256,\n",
       "                       0.0679,  0.1208,  0.0817, -0.0028, -0.0158, -0.0064,  0.1677,  0.0274,\n",
       "                       0.1743,  0.0086,  0.1202, -0.0396,  0.0501,  0.2169,  0.2939, -0.0370,\n",
       "                       0.0121, -0.0559,  0.1007,  0.1475,  0.1022,  0.2221,  0.1856,  0.0338,\n",
       "                       0.2002,  0.0920, -0.0097,  0.1521,  0.1083,  0.0957,  0.2687,  0.0480,\n",
       "                       0.1852, -0.0324,  0.1414,  0.1516,  0.0960,  0.0743,  0.0559, -0.0590,\n",
       "                       0.0126,  0.2514,  0.0602,  0.0673,  0.1790,  0.0504,  0.0589,  0.0926,\n",
       "                       0.0208,  0.1061,  0.1552,  0.1291,  0.0263,  0.2473, -0.0414,  0.2041])),\n",
       "             ('lstm.bias_hh_l1',\n",
       "              tensor([ 9.8880e-02,  1.3823e-01,  4.7600e-03,  1.2992e-01,  5.9296e-02,\n",
       "                       1.8910e-01, -8.7075e-03, -7.6164e-02, -1.7084e-02, -9.6833e-03,\n",
       "                       6.6051e-02,  6.6063e-03,  6.8192e-02,  2.9961e-02, -1.5457e-02,\n",
       "                       7.7741e-02,  2.2266e-02,  9.7290e-02,  1.0607e-01, -3.0439e-02,\n",
       "                       2.1263e-02,  7.3166e-02,  9.3965e-02,  6.3337e-02,  2.3544e-02,\n",
       "                       1.4984e-01,  1.8296e-02,  5.6680e-02,  6.7389e-02,  7.0397e-02,\n",
       "                       2.2175e-01,  1.4216e-01,  2.3857e-01,  2.1268e-02,  1.0973e-01,\n",
       "                       9.5350e-02, -7.9627e-02,  2.2072e-01,  4.3570e-02,  5.6573e-03,\n",
       "                       1.8868e-03,  1.2769e-01,  1.4994e-01,  1.5518e-01, -3.5966e-02,\n",
       "                       1.2718e-01,  4.3596e-02,  4.5765e-02,  8.5304e-03,  2.3892e-01,\n",
       "                       4.1229e-02, -2.0927e-02,  2.0790e-01,  2.1418e-01,  1.3535e-01,\n",
       "                      -4.0648e-02, -8.6746e-02,  4.9235e-03,  1.9767e-01,  1.3799e-01,\n",
       "                      -6.3791e-02,  1.5147e-01, -9.2507e-02,  1.9399e-01,  6.9314e-03,\n",
       "                       4.3846e-02, -1.4440e-02,  7.1736e-02,  9.3504e-02,  4.3188e-03,\n",
       "                       1.3950e-01, -3.9179e-03,  1.3285e-01, -1.7050e-02,  1.0396e-01,\n",
       "                      -4.2439e-02, -4.1044e-02, -6.7170e-02, -3.7564e-02,  1.0922e-01,\n",
       "                      -3.6836e-02,  3.6501e-02,  1.0806e-01,  6.1489e-02,  3.3921e-02,\n",
       "                      -6.0527e-02,  4.6669e-02,  6.1710e-02, -3.0708e-02, -3.4040e-02,\n",
       "                       8.5249e-02,  1.5847e-01, -1.5554e-02,  1.6723e-02,  5.1737e-02,\n",
       "                      -4.4853e-02,  1.5466e-01, -7.8507e-02,  7.6895e-03,  5.3044e-02,\n",
       "                       4.1485e-02,  2.0589e-03,  4.2468e-02,  6.2280e-02,  7.1676e-02,\n",
       "                       3.8965e-02,  1.3998e-01, -2.4556e-02, -4.4383e-02, -2.3327e-02,\n",
       "                      -2.0544e-02,  2.6342e-02,  4.9960e-02,  3.1445e-02,  1.0244e-01,\n",
       "                      -5.6238e-02, -1.1617e-01,  9.6008e-02,  1.0629e-01, -4.3837e-02,\n",
       "                       1.2481e-01,  3.9585e-02,  5.8157e-04, -5.9708e-02,  9.2242e-02,\n",
       "                       1.6025e-01, -4.2971e-02,  9.4636e-02,  2.1385e-01,  8.0585e-02,\n",
       "                       1.5922e-01, -3.0974e-01,  1.4903e-01,  6.1269e-02,  3.7090e-01,\n",
       "                       1.2467e-02,  3.1347e-01,  2.1290e-01,  8.8552e-02,  7.9054e-02,\n",
       "                      -3.0184e-01, -2.2470e-01, -2.2343e-01,  2.2682e-01,  3.1591e-01,\n",
       "                      -2.9419e-01,  3.1876e-01, -6.4696e-02,  1.6327e-01,  3.2197e-01,\n",
       "                      -2.6124e-01,  9.0191e-02,  1.4136e-01, -1.4208e-01, -3.8067e-01,\n",
       "                       1.6954e-01,  2.3160e-01, -2.7797e-01, -5.9137e-02,  1.2151e-01,\n",
       "                       4.4610e-01,  9.8263e-02, -1.3067e-01, -2.0612e-02,  2.2541e-01,\n",
       "                      -3.7500e-01,  4.4259e-01, -2.6381e-01,  2.3101e-01, -2.6790e-01,\n",
       "                       2.4770e-01,  1.4575e-01, -1.5057e-01, -1.8666e-01, -2.6586e-01,\n",
       "                       1.2242e-01,  3.2704e-01, -3.2481e-01,  2.2630e-01,  2.8524e-01,\n",
       "                      -1.5508e-01, -1.8150e-01, -1.4033e-01,  6.8508e-02,  9.2851e-02,\n",
       "                       1.8421e-02,  5.1775e-02, -6.6448e-02,  2.3700e-01,  3.3624e-01,\n",
       "                      -5.3920e-02,  1.1908e-01,  4.4711e-02,  8.4901e-02,  2.6506e-02,\n",
       "                       2.2842e-01,  1.5037e-01,  2.1744e-01,  1.0704e-01,  1.1330e-01,\n",
       "                      -2.8858e-02, -5.9935e-02,  1.5813e-01,  1.1053e-01,  1.8905e-01,\n",
       "                       1.0520e-01, -1.1945e-04,  6.6086e-02,  9.6380e-02,  2.0091e-01,\n",
       "                       2.3733e-01,  7.9511e-02,  3.9549e-02,  1.7335e-01,  1.5959e-01,\n",
       "                      -7.6179e-02,  2.8419e-02, -2.3291e-02,  2.1115e-01,  4.9293e-02,\n",
       "                       2.3539e-03,  1.1038e-01,  1.9861e-01,  3.3670e-02,  1.0316e-01,\n",
       "                       2.0111e-01, -1.4034e-02, -3.7916e-02, -7.3517e-02,  3.2041e-01,\n",
       "                       7.6767e-02,  7.6668e-03,  1.2446e-01,  4.8361e-02,  1.5963e-01,\n",
       "                       1.7555e-01,  9.9665e-02,  9.0005e-02,  3.8835e-02,  3.1053e-03,\n",
       "                       1.5547e-01,  2.4137e-01,  3.0879e-02, -6.2012e-02,  1.8518e-01,\n",
       "                       2.0201e-01,  1.0845e-01,  4.0619e-02,  6.4436e-02,  1.0678e-01,\n",
       "                       1.1209e-01,  4.0877e-02,  1.6105e-02,  1.5576e-01,  1.3021e-02,\n",
       "                       1.0640e-01])),\n",
       "             ('fc.weight',\n",
       "              tensor([[ 8.4995e-04, -2.5159e-02, -3.6274e-02,  ..., -1.4049e-01,\n",
       "                       -5.1498e-02,  8.9556e-02],\n",
       "                      [-9.3629e-02,  3.5870e-04, -4.2255e-02,  ..., -5.8271e-02,\n",
       "                        5.7174e-02, -1.4272e-02],\n",
       "                      [-8.9370e-02, -6.5790e-02,  5.3067e-02,  ..., -9.3037e-02,\n",
       "                        8.9616e-02, -8.9073e-03],\n",
       "                      ...,\n",
       "                      [ 5.6075e-02, -2.7440e-02, -1.9276e-02,  ..., -2.4381e-01,\n",
       "                        1.3088e-01,  7.0123e-02],\n",
       "                      [ 9.4304e-02, -1.9187e-02,  4.6059e-02,  ..., -2.5657e-01,\n",
       "                        9.4897e-02, -9.3609e-02],\n",
       "                      [-5.0636e-01,  3.8656e-02, -2.0538e-01,  ..., -4.2498e-02,\n",
       "                        1.2024e-02, -3.8385e-01]])),\n",
       "             ('fc.bias',\n",
       "              tensor([-0.3790, -0.4230, -0.4906, -0.3909,  0.1845, -0.5681, -0.4807, -0.4083,\n",
       "                       0.2251, -0.5218, -0.2439, -0.2581, -0.4815, -0.5427, -0.2599, -0.1554,\n",
       "                      -0.4976, -0.4697, -0.4518, -0.3807, -0.5053, -0.5175, -0.5348, -0.4434,\n",
       "                       0.9739, -0.4449,  1.3428, -0.5101, -0.3929, -0.3711,  0.4551, -0.0645,\n",
       "                      -0.4203, -0.3842,  0.0303]))])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\r\n",
    "x = torch.load(\"saved_weights.pt\")\r\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dictionaries...\n",
      "done\n",
      "Performing dataset pre-processing activities...\n",
      "loading dataset: ConLL2003-bioes-valid.txt\n",
      "done\n",
      "Parsing the dataset now...\n",
      "converting tokens to indices to tensors\n",
      "done\n",
      "Length matches! Hurray!\n",
      "loading dictionaries...\n",
      "done\n",
      "Step 02. builing the model...\n",
      "----------------------------------------------------------------\n",
      "Done! here is our model:\n",
      "RNNBIOESTagger(\n",
      "  (embedding): Embedding(30340, 50)\n",
      "  (lstm): LSTM(50, 32, num_layers=2, batch_first=True, dropout=0.2)\n",
      "  (fc): Linear(in_features=32, out_features=35, bias=True)\n",
      "  (activation_fn): Tanh()\n",
      ")\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RNNBIOESTagger(\n",
       "  (embedding): Embedding(30340, 50)\n",
       "  (lstm): LSTM(50, 32, num_layers=2, batch_first=True, dropout=0.2)\n",
       "  (fc): Linear(in_features=32, out_features=35, bias=True)\n",
       "  (activation_fn): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modelConLL2003 import RNNBIOESTagger\r\n",
    "from datasetConLL2003 import SlidingWindowDataset\r\n",
    "import torch\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "\r\n",
    "ds = SlidingWindowDataset(\"C:/Users/rahin/projects/paper-draft-03/data/raw/ConLL2003-bioes-valid.txt\")\r\n",
    "#ds = SlidingWindowDataset()\r\n",
    "x1, x2, y = ds.load_dictionaries()\r\n",
    "# read this seq2seq model: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html --> for understanding embedding dimension and output dimension  \r\n",
    "VOCAB_SIZE = len(x1)+len(x2)+2\r\n",
    "EMBED_DIM = 50\r\n",
    "HIDDEN_DIM = 32\r\n",
    "NUM_LAYERS = 2\r\n",
    "NUM_OF_CLASSES = len(y)+1\r\n",
    "EPOCHS = 5\r\n",
    "LEARNING_RATE = 0.5\r\n",
    "BATCH_SIZE = 64\r\n",
    "# Predictions\r\n",
    "\r\n",
    "print(\"Step 02. builing the model...\")\r\n",
    "model = RNNBIOESTagger(embedding_dimension= EMBED_DIM,\r\n",
    "                            vocabulary_size=VOCAB_SIZE,\r\n",
    "                            hidden_dimension=HIDDEN_DIM,\r\n",
    "                            num_of_layers=NUM_LAYERS,\r\n",
    "                            dropout=0.2,\r\n",
    "                            output_dimension=NUM_OF_CLASSES)\r\n",
    "print(\"----------------------------------------------------------------\")\r\n",
    "print(\"Done! here is our model:\")\r\n",
    "print(model)\r\n",
    "print(\"----------------------------------------------------------------\")\r\n",
    "\r\n",
    "\r\n",
    "model.load_state_dict(torch.load(\"C:/Users/rahin/projects/paper-draft-03/notebooks/conLLmodel.pth\"))\r\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets make predictions\n",
      "loading dictionaries...\n",
      "done\n",
      "Performing dataset pre-processing activities...\n",
      "loading dataset: ConLL2003-bioes-valid.txt\n",
      "done\n",
      "Parsing the dataset now...\n",
      "converting tokens to indices to tensors\n",
      "done\n",
      "Length matches! Hurray!\n",
      "{0: 'E-ADVP', 1: 'E-LST', 2: 'E-PRT', 3: 'I-CONJP', 4: 'O', 5: 'E-PP', 6: 'B-CONJP', 7: 'I-LST', 8: 'B-PP', 9: 'E-INTJ', 10: '-X-', 11: 'B', 12: 'E-ADJP', 13: 'E-VP', 14: 'B-ADVP', 15: 'I', 16: 'I-PRT', 17: 'B-SBAR', 18: 'I-ADVP', 19: 'B-INTJ', 20: 'I-SBAR', 21: 'I-PP', 22: 'B-PRT', 23: 'E', 24: 'I-NP', 25: 'I-ADJP', 26: 'B-NP', 27: 'B-ADJP', 28: 'E-SBAR', 29: 'E-NP', 30: 'B-VP', 31: 'I-VP', 32: 'B-LST', 34: 'PADDING'}\n",
      "tensor([[26, 24, 24, 24, 24, 24, 24, 24, 24, 24, 26, 26, 24, 24, 26, 24, 26, 34,\n",
      "         34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,\n",
      "         34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-c158d9ee3882>:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  idx_to_torch01 = torch.tensor(sentence, dtype=torch.int64)\n"
     ]
    }
   ],
   "source": [
    "idx_to_BIOES = {}\r\n",
    "print(\"Lets make predictions\")\r\n",
    "\r\n",
    "validation_dataset = DataLoader(dataset=SlidingWindowDataset(\"C:/Users/rahin/projects/paper-draft-03/data/raw/ConLL2003-bioes-valid.txt\"),\r\n",
    "                                batch_size=64,\r\n",
    "                                shuffle=True)\r\n",
    "\r\n",
    "for key, value in y.items():\r\n",
    "    idx_to_BIOES[value] = key\r\n",
    "\r\n",
    "print(idx_to_BIOES)\r\n",
    "# for idx, (sample, label) in enumerate(validation_dataset):\r\n",
    "\r\n",
    "#     if idx > 0:\r\n",
    "#         break\r\n",
    "# print(\"Our sample to predict:\")\r\n",
    "# print(sample[0])\r\n",
    "# print(\"Their actual label:\")\r\n",
    "# print(label[0])\r\n",
    "\r\n",
    "def predict(sentence, model):\r\n",
    "\r\n",
    "    \r\n",
    "    # print(f\"{tokens_in_line} \\n {tokens_to_idx}\")\r\n",
    "\r\n",
    "    # token idx to tensor conversion\r\n",
    "    #print(sentence)\r\n",
    "    idx_to_torch01 = torch.tensor(sentence, dtype=torch.int64)\r\n",
    "    idx_to_torch = idx_to_torch01.unsqueeze(1).T\r\n",
    "\r\n",
    "\r\n",
    "    with torch.no_grad():\r\n",
    "        output = model(idx_to_torch)\r\n",
    "        predicted_ouput=torch.argmax(output,dim=2)\r\n",
    "        print(predicted_ouput)\r\n",
    "        predicted_labels = []\r\n",
    "        for item in predicted_ouput:\r\n",
    "            for i in item:\r\n",
    "                predicted_labels.append(idx_to_BIOES[int(i)])\r\n",
    "        \r\n",
    "        return predicted_ouput, predicted_labels\r\n",
    "\r\n",
    "model = model.to(\"cpu\")\r\n",
    "\r\n",
    "example = sample[0]\r\n",
    "predicted_ouput, predictions_labels = predict(example, model)\r\n",
    "#print(predictions)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[26, 24, 24, 24, 24, 24, 24, 24, 24, 24, 26, 26, 24, 24, 26, 24, 26, 34,\n",
      "         34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,\n",
      "         34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34]])\n",
      "[tensor([[26, 24, 24,  ..., 34, 34, 34],\n",
      "        [26, 24, 26,  ..., 34, 34, 34],\n",
      "        [26, 30, 31,  ..., 34, 34, 34],\n",
      "        ...,\n",
      "        [26, 24, 24,  ..., 34, 34, 34],\n",
      "        [11, 26, 24,  ..., 34, 34, 34],\n",
      "        [26, 24, 26,  ..., 34, 34, 34]]), tensor([[11, 26, 15,  ..., 34, 34, 34],\n",
      "        [26, 24,  4,  ..., 34, 34, 34],\n",
      "        [26, 30, 26,  ..., 34, 34, 34],\n",
      "        ...,\n",
      "        [10, 26, 15,  ..., 34, 34, 34],\n",
      "        [26, 15, 26,  ..., 34, 34, 34],\n",
      "        [26, 30, 27,  ..., 34, 34, 34]]), tensor([[26, 24, 26,  ..., 34, 34, 34],\n",
      "        [11, 26, 26,  ..., 34, 34, 34],\n",
      "        [26, 29, 34,  ..., 34, 34, 34],\n",
      "        ...,\n",
      "        [26, 15, 26,  ..., 34, 34, 34],\n",
      "        [26, 24,  4,  ..., 34, 34, 34],\n",
      "        [26, 17, 26,  ..., 34, 34, 34]]), tensor([[11, 26, 24,  ..., 34, 34, 34],\n",
      "        [10, 26, 24,  ..., 34, 34, 34],\n",
      "        [26, 24,  4,  ..., 34, 34, 34],\n",
      "        ...,\n",
      "        [26, 24, 30,  ..., 34, 34, 34],\n",
      "        [26, 24, 26,  ..., 34, 34, 34],\n",
      "        [26, 30, 26,  ..., 34, 34, 34]]), tensor([[26,  8, 26,  ..., 34, 34, 34],\n",
      "        [11, 26, 15,  ..., 34, 34, 34],\n",
      "        [26, 30, 17,  ..., 34, 34, 34],\n",
      "        ...,\n",
      "        [26, 30, 26,  ..., 34, 34, 34],\n",
      "        [26, 24, 24,  ..., 34, 34, 34],\n",
      "        [10, 26, 24,  ..., 34, 34, 34]]), tensor([[26, 30, 31,  ..., 34, 34, 34],\n",
      "        [26, 24,  4,  ..., 34, 34, 34],\n",
      "        [26, 24,  4,  ..., 34, 34, 34],\n",
      "        ...,\n",
      "        [26, 30,  8,  ..., 34, 34, 34],\n",
      "        [26, 24, 24,  ..., 34, 34, 34],\n",
      "        [26, 24, 26,  ..., 34, 34, 34]]), tensor([[26, 24,  8,  ..., 34, 34, 34],\n",
      "        [ 8, 26, 24,  ..., 29, 34, 34],\n",
      "        [26, 30, 31,  ..., 34, 34, 34],\n",
      "        ...,\n",
      "        [26, 15, 26,  ..., 34, 34, 34],\n",
      "        [26, 30, 27,  ..., 34, 34, 34],\n",
      "        [10, 26, 24,  ..., 34, 34, 34]]), tensor([[26, 30,  8,  ..., 34, 34, 34],\n",
      "        [11, 26, 24,  ..., 34, 34, 34],\n",
      "        [26, 24, 26,  ..., 34, 34, 34],\n",
      "        ...,\n",
      "        [26, 24, 30,  ..., 34, 34, 34],\n",
      "        [11, 26, 24,  ..., 34, 34, 34],\n",
      "        [11,  8, 26,  ..., 34, 34, 34]]), tensor([[26, 24, 24,  ..., 34, 34, 34],\n",
      "        [26, 24, 24,  ..., 34, 34, 34],\n",
      "        [26, 24, 26,  ..., 34, 34, 34],\n",
      "        ...,\n",
      "        [26, 30, 26,  ..., 34, 34, 34],\n",
      "        [17, 26, 30,  ..., 34, 34, 34],\n",
      "        [26, 30, 31,  ..., 34, 34, 34]]), tensor([[26, 24, 26,  ..., 34, 34, 34],\n",
      "        [11, 26, 15,  ..., 34, 34, 34],\n",
      "        [10, 26, 26,  ..., 34, 34, 34],\n",
      "        ...,\n",
      "        [26, 24, 24,  ..., 34, 34, 34],\n",
      "        [11, 26, 30,  ..., 34, 34, 34],\n",
      "        [26,  8, 26,  ..., 34, 34, 34]]), tensor([[11, 26, 30,  ..., 34, 34, 34],\n",
      "        [26, 24, 24,  ..., 34, 34, 34],\n",
      "        [26, 24, 24,  ..., 34, 34, 34],\n",
      "        ...,\n",
      "        [10, 26, 24,  ..., 34, 34, 34],\n",
      "        [11, 14, 15,  ..., 34, 34, 34],\n",
      "        [26, 24, 30,  ..., 34, 34, 34]]), tensor([[26, 24, 30,  ..., 34, 34, 34],\n",
      "        [26, 24,  8,  ..., 34, 34, 34],\n",
      "        [26, 30, 26,  ..., 34, 34, 34],\n",
      "        ...,\n",
      "        [30, 26, 26,  ..., 34, 34, 34],\n",
      "        [11, 26, 14,  ..., 34, 34, 34],\n",
      "        [26, 24, 24,  ..., 34, 34, 34]]), tensor([[17, 30, 26,  ..., 34, 34, 34],\n",
      "        [26, 24, 26,  ..., 34, 34, 34],\n",
      "        [26,  8, 26,  ..., 34, 34, 34],\n",
      "        ...,\n",
      "        [26, 24, 24,  ..., 34, 34, 34],\n",
      "        [11,  4,  4,  ..., 34, 34, 34],\n",
      "        [10, 26, 24,  ..., 34, 34, 34]]), tensor([[11, 26, 26,  ..., 34, 34, 34],\n",
      "        [10, 26, 15,  ..., 34, 34, 34],\n",
      "        [26, 15, 26,  ..., 34, 34, 34],\n",
      "        ...,\n",
      "        [26, 30, 31,  ..., 34, 34, 34],\n",
      "        [26, 24, 30,  ..., 34, 34, 34],\n",
      "        [ 8, 26, 15,  ..., 34, 34, 34]]), tensor([[26, 24,  4,  ..., 34, 34, 34],\n",
      "        [ 8, 26, 15,  ..., 34, 34, 34],\n",
      "        [26, 24, 24,  ..., 34, 34, 34],\n",
      "        ...,\n",
      "        [26, 30, 31,  ..., 34, 34, 34],\n",
      "        [26, 24,  8,  ..., 34, 34, 34],\n",
      "        [26, 24, 26,  ..., 34, 34, 34]]), tensor([[26, 30,  8,  ..., 34, 34, 34],\n",
      "        [10, 30, 15,  ..., 34, 34, 34],\n",
      "        [10, 26, 15,  ..., 34, 34, 34],\n",
      "        ...,\n",
      "        [26, 30, 26,  ..., 34, 34, 34],\n",
      "        [26, 24,  8,  ..., 34, 34, 34],\n",
      "        [26, 24,  4,  ..., 34, 34, 34]]), tensor([[11, 26, 30,  ..., 34, 34, 34],\n",
      "        [26, 24, 26,  ..., 34, 34, 34],\n",
      "        [26, 14, 30,  ..., 34, 34, 34],\n",
      "        ...,\n",
      "        [26, 24, 26,  ..., 34, 34, 34],\n",
      "        [26, 24, 30,  ..., 34, 34, 34],\n",
      "        [26, 24, 24,  ..., 34, 34, 34]]), tensor([[11, 26, 15,  ..., 34, 34, 34],\n",
      "        [26, 26, 24,  ..., 34, 34, 34],\n",
      "        [26, 30, 31,  ..., 34, 34, 34],\n",
      "        ...,\n",
      "        [11, 26, 30,  ..., 34, 34, 34],\n",
      "        [26, 15, 26,  ..., 34, 34, 34],\n",
      "        [26, 24, 24,  ..., 34, 34, 34]]), tensor([[11, 26, 24,  ..., 34, 34, 34],\n",
      "        [26, 30, 26,  ..., 34, 34, 34],\n",
      "        [10, 26, 24,  ..., 34, 34, 34],\n",
      "        ...,\n",
      "        [26, 24, 24,  ..., 34, 34, 34],\n",
      "        [11, 26, 24,  ..., 34, 34, 34],\n",
      "        [26, 24,  8,  ..., 34, 34, 34]]), tensor([[10, 26, 15,  ..., 34, 34, 34],\n",
      "        [26, 15, 26,  ..., 24, 29, 34],\n",
      "        [26, 24,  8,  ..., 34, 34, 34],\n",
      "        ...,\n",
      "        [11,  8, 26,  ..., 34, 34, 34],\n",
      "        [26, 14, 30,  ..., 34, 34, 34],\n",
      "        [10, 26, 24,  ..., 34, 34, 34]]), tensor([[11, 17, 26,  ..., 34, 34, 34],\n",
      "        [26, 24, 26,  ..., 34, 34, 34],\n",
      "        [26, 24, 30,  ..., 34, 34, 34],\n",
      "        ...,\n",
      "        [26, 30, 26,  ..., 34, 34, 34],\n",
      "        [26, 24, 26,  ..., 34, 34, 34],\n",
      "        [26, 30, 31,  ..., 34, 34, 34]]), tensor([[26, 24, 30,  ..., 34, 34, 34],\n",
      "        [11, 26, 30,  ..., 34, 34, 34],\n",
      "        [26, 15, 26,  ..., 34, 34, 34],\n",
      "        ...,\n",
      "        [11,  8, 26,  ..., 34, 34, 34],\n",
      "        [26, 30, 26,  ..., 34, 34, 34],\n",
      "        [26, 24, 30,  ..., 34, 34, 34]]), tensor([[26, 30, 26,  ..., 34, 34, 34],\n",
      "        [26, 24, 30,  ..., 34, 34, 34],\n",
      "        [ 8, 26, 24,  ..., 34, 34, 34],\n",
      "        ...,\n",
      "        [10, 26, 26,  ..., 34, 34, 34],\n",
      "        [26, 24, 14,  ..., 34, 34, 34],\n",
      "        [30, 26, 26,  ..., 34, 34, 34]]), tensor([[26, 24, 30,  ..., 34, 34, 34],\n",
      "        [10, 26, 15,  ..., 34, 34, 34],\n",
      "        [26, 30, 26,  ..., 34, 34, 34],\n",
      "        ...,\n",
      "        [26, 24,  8,  ..., 34, 34, 34],\n",
      "        [11, 26, 24,  ..., 34, 34, 34],\n",
      "        [26, 30, 31,  ..., 34, 34, 34]]), tensor([[10, 26, 24,  ..., 34, 34, 34],\n",
      "        [26, 24, 24,  ..., 34, 34, 34],\n",
      "        [11,  8, 26,  ..., 34, 34, 34],\n",
      "        ...,\n",
      "        [26,  8, 26,  ..., 34, 34, 34],\n",
      "        [26, 24, 26,  ..., 34, 34, 34],\n",
      "        [10, 26, 24,  ..., 34, 34, 34]]), tensor([[26, 30, 26,  ..., 34, 34, 34],\n",
      "        [10, 26, 30,  ..., 34, 34, 34],\n",
      "        [11, 26, 24,  ..., 34, 34, 34],\n",
      "        ...,\n",
      "        [11, 26, 24,  ..., 34, 34, 34],\n",
      "        [26, 24, 26,  ..., 34, 34, 34],\n",
      "        [26, 24, 24,  ..., 26,  8, 29]]), tensor([[26, 24, 26,  ..., 34, 34, 34],\n",
      "        [26, 30, 31,  ..., 34, 34, 34],\n",
      "        [11,  8, 26,  ..., 34, 34, 34],\n",
      "        ...,\n",
      "        [26, 24, 24,  ..., 34, 34, 34],\n",
      "        [26, 15, 30,  ..., 34, 34, 34],\n",
      "        [11, 26, 24,  ..., 34, 34, 34]]), tensor([[26, 24, 30,  ..., 34, 34, 34],\n",
      "        [26, 24, 24,  ..., 34, 34, 34],\n",
      "        [17, 26, 30,  ..., 34, 34, 34],\n",
      "        ...,\n",
      "        [26,  8, 26,  ..., 34, 34, 34],\n",
      "        [26, 30, 27,  ..., 34, 34, 34],\n",
      "        [26, 24, 30,  ..., 34, 34, 34]])]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'sum'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-1b6a2e6aa5a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mbinary_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_ouput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-43-1b6a2e6aa5a9>\u001b[0m in \u001b[0;36mbinary_accuracy\u001b[1;34m(preds, y)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;31m# print(len(y))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'bool' object has no attribute 'sum'"
     ]
    }
   ],
   "source": [
    "\r\n",
    "def binary_accuracy(preds, y):\r\n",
    "    print(preds)\r\n",
    "    print(y)\r\n",
    "\r\n",
    "    correct = (preds == y)\r\n",
    "    print(correct.sum() / len(y))\r\n",
    "    # print(len(y))\r\n",
    "\r\n",
    "    # # correct = (rounded_preds == y).float() \r\n",
    "\r\n",
    "    # _,pred_label = torch.max(rounded_preds[-1], dim=0)\r\n",
    "    # correct = (pred_label == y).float()\r\n",
    "    acc = correct.sum() / len(y)\r\n",
    "    return acc\r\n",
    "\r\n",
    "binary_accuracy(predicted_ouput, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, labels = [], []\r\n",
    "for idx, (sample, label) in enumerate(validation_dataset):\r\n",
    "    samples.append(sample)\r\n",
    "    labels.append(label)\r\n",
    "\r\n",
    "#     if idx > 0:\r\n",
    "#         break\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "75c4db28bb58e6de10e05be21b6046b5ba21d9aba4af4007d97c2f3325bc0896"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('tf': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}